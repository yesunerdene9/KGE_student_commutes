{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: panda in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.3.1)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from panda) (68.2.2)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from panda) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->panda) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->panda) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->panda) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->panda) (2024.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (17.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyarrow) (1.26.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1310543"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "\n",
    "table = pq.read_table('timediaries.parquet')\n",
    "df = table.to_pandas()\n",
    "df.size\n",
    "# df['A1_What are you doing?'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created.\n",
      "   userid                timestamp                               activity  \\\n",
      "0       0  2018-05-09 19:33:48.395         Guardo Youtube, Serie-Tv, ecc.   \n",
      "1       0  2018-05-09 21:09:51.600  Cinema, Teatro, Concerto, Mostra, ...   \n",
      "2       0  2018-05-09 21:32:45.845         Guardo Youtube, Serie-Tv, ecc.   \n",
      "3       0  2018-05-09 23:33:07.865         Leggo un libro; ascolto musica   \n",
      "4       0  2018-05-10 00:02:20.655                                Dormire   \n",
      "\n",
      "         duration  \n",
      "0    96 min 3 sec  \n",
      "1   22 min 54 sec  \n",
      "2  120 min 22 sec  \n",
      "3   29 min 12 sec  \n",
      "4  755 min 54 sec  \n"
     ]
    }
   ],
   "source": [
    "# generating csv for activity stream\n",
    "\n",
    "table = pq.read_table('timediaries.parquet')\n",
    "df = table.to_pandas()\n",
    "df.size\n",
    "\n",
    "df['activity'] = df['A1_What are you doing?']\n",
    "df['timestamp'] = pd.to_datetime(df['answertimestamp'])\n",
    "\n",
    "df = df.sort_values(by=['userid', 'timestamp'])\n",
    "\n",
    "df['activity_change'] = (df['activity'] != df['activity'].shift(1)) | (df['userid'] != df['userid'].shift(1))\n",
    "df['activity_block'] = df['activity_change'].cumsum()\n",
    "\n",
    "df['next_timestamp'] = df.groupby('userid')['timestamp'].shift(-1)  # Get the next timestamp within each user group\n",
    "df['duration_seconds'] = (df['next_timestamp'] - df['timestamp']).dt.total_seconds().fillna(0)\n",
    "\n",
    "\n",
    "grouped = df.groupby(['userid', 'activity', 'activity_block']).agg({'duration_seconds': 'sum'}).reset_index()\n",
    "\n",
    "grouped['minutes'] = (grouped['duration_seconds'] // 60).astype(int) \n",
    "grouped['seconds'] = (grouped['duration_seconds'] % 60).astype(int)\n",
    "\n",
    "grouped['duration'] = grouped.apply(lambda row: f\"{row['minutes']} min {row['seconds']} sec\", axis=1)\n",
    "\n",
    "merged_df = pd.merge(df[['userid', 'timestamp', 'activity', 'activity_block']], \n",
    "                     grouped[['userid', 'activity_block', 'duration']], \n",
    "                     on=['userid', 'activity_block'], \n",
    "                     how='left')\n",
    "\n",
    "merged_df = merged_df.drop_duplicates(subset=['userid', 'activity_block'])\n",
    "\n",
    "merged_df[['userid', 'timestamp', 'activity', 'duration']].to_csv('activity_stream.csv', index=False)\n",
    "\n",
    "print(\"CSV file created.\")\n",
    "\n",
    "activity_df = pd.read_csv('activity_stream.csv')\n",
    "\n",
    "print(activity_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique emojis in the dataset: ['üòä' 'üòÅ' nan 'üòê' 'üòû' 'üôÅ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experimentid</th>\n",
       "      <th>userid</th>\n",
       "      <th>questiontimestamp</th>\n",
       "      <th>answerduration</th>\n",
       "      <th>answertimestamp</th>\n",
       "      <th>delta</th>\n",
       "      <th>notificationtimestamp</th>\n",
       "      <th>questionid</th>\n",
       "      <th>A1_What are you doing?</th>\n",
       "      <th>A2_How are you moving?</th>\n",
       "      <th>A3_Where are you?</th>\n",
       "      <th>A5_With whom are you?</th>\n",
       "      <th>A6_What is your mood?</th>\n",
       "      <th>mood</th>\n",
       "      <th>mood_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100806</th>\n",
       "      <td>smartUnitnII</td>\n",
       "      <td>157</td>\n",
       "      <td>2018-06-07 09:51:21.624</td>\n",
       "      <td>4007</td>\n",
       "      <td>2018-06-07 10:14:25.390</td>\n",
       "      <td>1384173</td>\n",
       "      <td>2018-06-07 09:51:21.217</td>\n",
       "      <td>d0d78160ab3d87c7c6949e90a5897d7f49fa2486</td>\n",
       "      <td>Studio</td>\n",
       "      <td>Biblioteca UNITN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Da solo</td>\n",
       "      <td>üòä</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100807</th>\n",
       "      <td>smartUnitnII</td>\n",
       "      <td>157</td>\n",
       "      <td>2018-06-07 13:51:21.534</td>\n",
       "      <td>4434</td>\n",
       "      <td>2018-06-07 13:51:37.486</td>\n",
       "      <td>16216</td>\n",
       "      <td>2018-06-07 13:51:21.270</td>\n",
       "      <td>d0d78160ab3d87c7c6949e90a5897d7f49fa2486</td>\n",
       "      <td>Studio</td>\n",
       "      <td>Biblioteca UNITN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Da solo</td>\n",
       "      <td>üòä</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100808</th>\n",
       "      <td>smartUnitnII</td>\n",
       "      <td>157</td>\n",
       "      <td>2018-06-07 15:51:21.530</td>\n",
       "      <td>5875</td>\n",
       "      <td>2018-06-07 16:27:00.180</td>\n",
       "      <td>2139027</td>\n",
       "      <td>2018-06-07 15:51:21.153</td>\n",
       "      <td>d0d78160ab3d87c7c6949e90a5897d7f49fa2486</td>\n",
       "      <td>Studio</td>\n",
       "      <td>Biblioteca UNITN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Partner</td>\n",
       "      <td>üòä</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100809</th>\n",
       "      <td>smartUnitnII</td>\n",
       "      <td>157</td>\n",
       "      <td>2018-06-07 17:51:21.519</td>\n",
       "      <td>5217</td>\n",
       "      <td>2018-06-07 17:51:53.257</td>\n",
       "      <td>12413</td>\n",
       "      <td>2018-06-07 17:51:40.844</td>\n",
       "      <td>d0d78160ab3d87c7c6949e90a5897d7f49fa2486</td>\n",
       "      <td>Studio</td>\n",
       "      <td>Biblioteca UNITN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Partner</td>\n",
       "      <td>üòä</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100810</th>\n",
       "      <td>smartUnitnII</td>\n",
       "      <td>157</td>\n",
       "      <td>2018-06-07 21:51:21.516</td>\n",
       "      <td>5036</td>\n",
       "      <td>2018-06-07 22:06:50.274</td>\n",
       "      <td>929148</td>\n",
       "      <td>2018-06-07 21:51:21.126</td>\n",
       "      <td>d0d78160ab3d87c7c6949e90a5897d7f49fa2486</td>\n",
       "      <td>Studio</td>\n",
       "      <td>Casa, Appartamento, Stanza</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Da solo</td>\n",
       "      <td>üòä</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        experimentid  userid        questiontimestamp  answerduration  \\\n",
       "100806  smartUnitnII     157  2018-06-07 09:51:21.624            4007   \n",
       "100807  smartUnitnII     157  2018-06-07 13:51:21.534            4434   \n",
       "100808  smartUnitnII     157  2018-06-07 15:51:21.530            5875   \n",
       "100809  smartUnitnII     157  2018-06-07 17:51:21.519            5217   \n",
       "100810  smartUnitnII     157  2018-06-07 21:51:21.516            5036   \n",
       "\n",
       "                answertimestamp    delta    notificationtimestamp  \\\n",
       "100806  2018-06-07 10:14:25.390  1384173  2018-06-07 09:51:21.217   \n",
       "100807  2018-06-07 13:51:37.486    16216  2018-06-07 13:51:21.270   \n",
       "100808  2018-06-07 16:27:00.180  2139027  2018-06-07 15:51:21.153   \n",
       "100809  2018-06-07 17:51:53.257    12413  2018-06-07 17:51:40.844   \n",
       "100810  2018-06-07 22:06:50.274   929148  2018-06-07 21:51:21.126   \n",
       "\n",
       "                                      questionid A1_What are you doing?  \\\n",
       "100806  d0d78160ab3d87c7c6949e90a5897d7f49fa2486                 Studio   \n",
       "100807  d0d78160ab3d87c7c6949e90a5897d7f49fa2486                 Studio   \n",
       "100808  d0d78160ab3d87c7c6949e90a5897d7f49fa2486                 Studio   \n",
       "100809  d0d78160ab3d87c7c6949e90a5897d7f49fa2486                 Studio   \n",
       "100810  d0d78160ab3d87c7c6949e90a5897d7f49fa2486                 Studio   \n",
       "\n",
       "            A2_How are you moving? A3_Where are you? A5_With whom are you?  \\\n",
       "100806            Biblioteca UNITN               NaN               Da solo   \n",
       "100807            Biblioteca UNITN               NaN               Da solo   \n",
       "100808            Biblioteca UNITN               NaN               Partner   \n",
       "100809            Biblioteca UNITN               NaN               Partner   \n",
       "100810  Casa, Appartamento, Stanza               NaN               Da solo   \n",
       "\n",
       "       A6_What is your mood?  mood mood_text  \n",
       "100806                     üòä     3     happy  \n",
       "100807                     üòä     3     happy  \n",
       "100808                     üòä     3     happy  \n",
       "100809                     üòä     3     happy  \n",
       "100810                     üòä     3     happy  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maps emojis to numerics\n",
    "\n",
    "table = pq.read_table('timediaries.parquet')\n",
    "dataset = table.to_pandas().to_csv('dataset.csv', index=False)\n",
    "\n",
    "df = pd.read_csv('dataset.csv')\n",
    "df.head()\n",
    "\n",
    "unique_emojis = df['A6_What is your mood?'].unique()\n",
    "print(\"Unique emojis in the dataset:\", unique_emojis)\n",
    "emoji_meaning_mapping = {\n",
    "    'üòû': 0,  # sad\n",
    "    'üôÅ': 1,  # down\n",
    "    'üòê': 2,  # neutral\n",
    "    'üòä': 3,  # happy\n",
    "    'üòÅ': 4,  # excited\n",
    "    # '<NA>': 5,  # unanswered\n",
    "}\n",
    "emoji_text_mapping = {\n",
    "    'üòû': 'sad',\n",
    "    'üôÅ': 'down', \n",
    "    'üòê': 'neutral',\n",
    "    'üòä': 'happy', \n",
    "    'üòÅ': 'excited',\n",
    "    # '<NA>': 'unanswered' \n",
    "}\n",
    "\n",
    "df['mood'] = df['A6_What is your mood?'].map(emoji_meaning_mapping)\n",
    "df['mood'] = df['mood'].fillna(5).astype(int)\n",
    "\n",
    "unmapped_moods = df[df['mood'].isna()]['A6_What is your mood?'].unique()\n",
    "if len(unmapped_moods) > 0:\n",
    "    print(\"Unmapped moods (emojis):\", unmapped_moods)\n",
    "# df.head()\n",
    "\n",
    "\n",
    "df['mood_text'] = df['A6_What is your mood?'].map(emoji_text_mapping)\n",
    "df['mood_text'] = df['mood_text'].fillna('unanswered')\n",
    "\n",
    "unmapped_moods = df[df['mood_text'].isna()]['A6_What is your mood?'].unique()\n",
    "if len(unmapped_moods) > 0:\n",
    "    print(\"Unmapped moods (emojis):\", unmapped_moods)\n",
    "\n",
    "# df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created.\n",
      "   userid                timestamp  mood   mood_text            duration\n",
      "0       0  2018-05-09 19:33:48.395     3       happy  180.0 min 25.0 sec\n",
      "1       0  2018-05-09 22:34:13.508     4     excited    88.0 min 7.0 sec\n",
      "2       0  2018-05-10 00:02:20.655     5  unanswered  755.0 min 54.0 sec\n",
      "3       0  2018-05-10 12:38:14.671     3       happy   73.0 min 13.0 sec\n",
      "4       0  2018-05-10 13:51:27.778     4     excited   12.0 min 41.0 sec\n"
     ]
    }
   ],
   "source": [
    "# generating csv for mood stream\n",
    "\n",
    "df['mood_emj'] = df['A6_What is your mood?']\n",
    "df['timestamp'] = pd.to_datetime(df['answertimestamp'])\n",
    "\n",
    "df = df.sort_values(by=['userid', 'timestamp'])\n",
    "\n",
    "df['mood_change'] = (df['mood'] != df['mood'].shift(1)) | (df['userid'] != df['userid'].shift(1))\n",
    "df['mood_block'] = df['mood_change'].cumsum()\n",
    "\n",
    "df['next_timestamp'] = df.groupby('userid')['timestamp'].shift(-1)  # Get the next timestamp within each user group\n",
    "df['duration_seconds'] = (df['next_timestamp'] - df['timestamp']).dt.total_seconds().fillna(0)\n",
    "\n",
    "\n",
    "grouped = df.groupby(['userid', 'mood', 'mood_block']).agg({'duration_seconds': 'sum'}).reset_index()\n",
    "\n",
    "grouped['minutes'] = (grouped['duration_seconds'] // 60).astype(int) \n",
    "grouped['seconds'] = (grouped['duration_seconds'] % 60).astype(int)\n",
    "\n",
    "grouped['duration'] = grouped.apply(lambda row: f\"{row['minutes']} min {row['seconds']} sec\", axis=1)\n",
    "\n",
    "merged_df = pd.merge(df[['userid', 'timestamp', 'mood', 'mood_emj', 'mood_text', 'mood_block']], \n",
    "                     grouped[['userid', 'mood_block', 'duration']], \n",
    "                     on=['userid', 'mood_block'], \n",
    "                     how='left')\n",
    "\n",
    "merged_df = merged_df.drop_duplicates(subset=['userid', 'mood_block'])\n",
    "\n",
    "merged_df[['userid', 'timestamp', 'mood', 'mood_text', 'duration']].to_csv('mood_stream.csv', index=False)\n",
    "\n",
    "print(\"CSV file created.\")\n",
    "\n",
    "mood_df = pd.read_csv('mood_stream.csv')\n",
    "\n",
    "mood_df.size\n",
    "print(mood_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_value(value):\n",
    "    \n",
    "    try:\n",
    "        if '.' in value:\n",
    "            return float(value)\n",
    "        elif len(value) > 10:\n",
    "                return value\n",
    "        else:\n",
    "            return int(value)\n",
    "    except ValueError:\n",
    "        return value \n",
    "\n",
    "def csv_to_json(csv_file, json_file):\n",
    "    \n",
    "    with open(csv_file, mode='r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        rows = []\n",
    "        for row in reader:\n",
    "            converted_row = {key: convert_value(value) for key, value in row.items()}\n",
    "            rows.append(converted_row)\n",
    "\n",
    "    with open(json_file, mode='w') as f:\n",
    "        json.dump(rows, f, indent=4)\n",
    "\n",
    "csv_file = \"../auxilary datas/activity_stream.csv\"\n",
    "json_file = \"../auxilary datas/activity_stream.json\"\n",
    "csv_to_json(csv_file, json_file)\n",
    "csv_file = \"../auxilary datas/mood_stream.csv\"\n",
    "json_file = \"../auxilary datas/mood_stream.json\"\n",
    "csv_to_json(csv_file, json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
